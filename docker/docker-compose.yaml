version: "3.8"

# KnightGPT Full Stack Deployment
# Includes: API Server, Open WebUI, Neo4j (optional)
# For deployment at knight-lab-dev.org

services:
  # KnightGPT RAG API
  api:
    build:
      context: ..
      dockerfile: docker/Dockerfile.api
    container_name: knightgpt-api
    restart: unless-stopped
    ports:
      - "8080:8080"
    environment:
      - VLLM_EMBEDDING_URL=${VLLM_EMBEDDING_URL:-http://host.docker.internal:8001/v1}
      - VLLM_INFERENCE_URL=${VLLM_INFERENCE_URL:-http://host.docker.internal:8000/v1}
      - VLLM_EMBEDDING_MODEL=${VLLM_EMBEDDING_MODEL:-Alibaba-NLP/gte-Qwen2-7B-instruct}
      - VLLM_INFERENCE_MODEL=${VLLM_INFERENCE_MODEL:-meta-llama/Llama-3.3-70B-Instruct}
      - NEO4J_URI=bolt://neo4j:7687
      - NEO4J_USER=neo4j
      - NEO4J_PASSWORD=${NEO4J_PASSWORD:-password}
      - LOG_LEVEL=INFO
    volumes:
      - ../data:/app/data:ro
      - api-logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - knightgpt-net
    depends_on:
      - neo4j

  # Open WebUI - Self-hosted ChatGPT-like interface
  # https://github.com/open-webui/open-webui
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: knightgpt-webui
    restart: unless-stopped
    ports:
      - "3000:8080"
    environment:
      # Connect to KnightGPT API as OpenAI-compatible endpoint
      - OPENAI_API_BASE_URL=http://api:8080/v1
      - OPENAI_API_KEY=EMPTY
      # Enable web search (optional)
      - ENABLE_RAG_WEB_SEARCH=true
      - RAG_WEB_SEARCH_ENGINE=searxng
      # Authentication
      - WEBUI_AUTH=true
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY:-changeme}
      # Disable Ollama since we're using vLLM
      - OLLAMA_BASE_URL=
    volumes:
      - open-webui-data:/app/backend/data
    networks:
      - knightgpt-net
    depends_on:
      - api

  # Neo4j Graph Database (optional, for persistent storage)
  neo4j:
    image: neo4j:5.16-community
    container_name: knightgpt-neo4j
    restart: unless-stopped
    ports:
      - "7474:7474"  # HTTP
      - "7687:7687"  # Bolt
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-password}
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
      - NEO4J_dbms_memory_heap_initial__size=512m
      - NEO4J_dbms_memory_heap_max__size=2G
    volumes:
      - neo4j-data:/data
      - neo4j-logs:/logs
    networks:
      - knightgpt-net

  # Watchtower - Automatic container updates
  watchtower:
    image: containrrr/watchtower
    container_name: knightgpt-watchtower
    restart: unless-stopped
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    environment:
      - WATCHTOWER_CLEANUP=true
      - WATCHTOWER_POLL_INTERVAL=86400  # Check daily
      - WATCHTOWER_INCLUDE_STOPPED=true
    command: --interval 86400 knightgpt-webui knightgpt-api

  # Cloudflare Tunnel (for secure external access)
  # Requires: cloudflared tunnel login
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: knightgpt-cloudflared
    restart: unless-stopped
    command: tunnel --no-autoupdate run
    environment:
      - TUNNEL_TOKEN=${CLOUDFLARE_TUNNEL_TOKEN}
    networks:
      - knightgpt-net
    depends_on:
      - open-webui
    profiles:
      - production

volumes:
  api-logs:
  open-webui-data:
  neo4j-data:
  neo4j-logs:

networks:
  knightgpt-net:
    driver: bridge
